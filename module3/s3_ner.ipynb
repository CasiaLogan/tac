{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reconnaissance d'entités nommées avec SpaCy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La documentation est accessible ici: https://spacy.io/api"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fr_core_news_md in /home/max/git/tac/venv/lib/python3.11/site-packages (3.8.0)\n",
      "\u001b[33mDEPRECATION: textract 1.6.5 has a non-standard dependency specifier extract-msg<=0.29.*. pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of textract or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import spacy\n",
    "from spacy.lang.fr.examples import sentences\n",
    "%pip install  fr_core_news_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\casia\\testTAC\\tac\\.venv\\Lib\\site-packages\\spacy\\util.py:887: UserWarning: [W095] Model 'fr_core_news_md' (3.8.0) was trained with spaCy v3.8 and may not be 100% compatible with the current version (3.5.2). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "ename": "RegistryError",
     "evalue": "[E892] Unknown function registry: 'vectors'.\n\nAvailable names: architectures, augmenters, batchers, callbacks, cli, datasets, displacy_colors, factories, initializers, languages, layers, lemmatizers, loggers, lookups, losses, misc, models, ops, optimizers, readers, schedules, scorers, tokenizers",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRegistryError\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m nlp = \u001b[43mspacy\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mfr_core_news_md\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\casia\\testTAC\\tac\\.venv\\Lib\\site-packages\\spacy\\__init__.py:54\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(name, vocab, disable, enable, exclude, config)\u001b[39m\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload\u001b[39m(\n\u001b[32m     31\u001b[39m     name: Union[\u001b[38;5;28mstr\u001b[39m, Path],\n\u001b[32m     32\u001b[39m     *,\n\u001b[32m   (...)\u001b[39m\u001b[32m     37\u001b[39m     config: Union[Dict[\u001b[38;5;28mstr\u001b[39m, Any], Config] = util.SimpleFrozenDict(),\n\u001b[32m     38\u001b[39m ) -> Language:\n\u001b[32m     39\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Load a spaCy model from an installed package or a local path.\u001b[39;00m\n\u001b[32m     40\u001b[39m \n\u001b[32m     41\u001b[39m \u001b[33;03m    name (str): Package name or model path.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     52\u001b[39m \u001b[33;03m    RETURNS (Language): The loaded nlp object.\u001b[39;00m\n\u001b[32m     53\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m54\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mutil\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     55\u001b[39m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     56\u001b[39m \u001b[43m        \u001b[49m\u001b[43mvocab\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvocab\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     57\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdisable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdisable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     58\u001b[39m \u001b[43m        \u001b[49m\u001b[43menable\u001b[49m\u001b[43m=\u001b[49m\u001b[43menable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     59\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexclude\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexclude\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     60\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     61\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\casia\\testTAC\\tac\\.venv\\Lib\\site-packages\\spacy\\util.py:442\u001b[39m, in \u001b[36mload_model\u001b[39m\u001b[34m(name, vocab, disable, enable, exclude, config)\u001b[39m\n\u001b[32m    440\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m get_lang_class(name.replace(\u001b[33m\"\u001b[39m\u001b[33mblank:\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m))()\n\u001b[32m    441\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_package(name):  \u001b[38;5;66;03m# installed as package\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m442\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mload_model_from_package\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[32m    443\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m Path(name).exists():  \u001b[38;5;66;03m# path to model data directory\u001b[39;00m\n\u001b[32m    444\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m load_model_from_path(Path(name), **kwargs)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\casia\\testTAC\\tac\\.venv\\Lib\\site-packages\\spacy\\util.py:478\u001b[39m, in \u001b[36mload_model_from_package\u001b[39m\u001b[34m(name, vocab, disable, enable, exclude, config)\u001b[39m\n\u001b[32m    461\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Load a model from an installed package.\u001b[39;00m\n\u001b[32m    462\u001b[39m \n\u001b[32m    463\u001b[39m \u001b[33;03mname (str): The package name.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    475\u001b[39m \u001b[33;03mRETURNS (Language): The loaded nlp object.\u001b[39;00m\n\u001b[32m    476\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    477\u001b[39m \u001b[38;5;28mcls\u001b[39m = importlib.import_module(name)\n\u001b[32m--> \u001b[39m\u001b[32m478\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvocab\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvocab\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdisable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdisable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menable\u001b[49m\u001b[43m=\u001b[49m\u001b[43menable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexclude\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexclude\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\casia\\testTAC\\tac\\.venv\\Lib\\site-packages\\fr_core_news_md\\__init__.py:10\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(**overrides)\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload\u001b[39m(**overrides):\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mload_model_from_init_py\u001b[49m\u001b[43m(\u001b[49m\u001b[34;43m__file__\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43moverrides\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\casia\\testTAC\\tac\\.venv\\Lib\\site-packages\\spacy\\util.py:659\u001b[39m, in \u001b[36mload_model_from_init_py\u001b[39m\u001b[34m(init_file, vocab, disable, enable, exclude, config)\u001b[39m\n\u001b[32m    657\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m model_path.exists():\n\u001b[32m    658\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(Errors.E052.format(path=data_path))\n\u001b[32m--> \u001b[39m\u001b[32m659\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mload_model_from_path\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    660\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    661\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvocab\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvocab\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    662\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmeta\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmeta\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    663\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdisable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdisable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    664\u001b[39m \u001b[43m    \u001b[49m\u001b[43menable\u001b[49m\u001b[43m=\u001b[49m\u001b[43menable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    665\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexclude\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexclude\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    666\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    667\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\casia\\testTAC\\tac\\.venv\\Lib\\site-packages\\spacy\\util.py:516\u001b[39m, in \u001b[36mload_model_from_path\u001b[39m\u001b[34m(model_path, meta, vocab, disable, enable, exclude, config)\u001b[39m\n\u001b[32m    514\u001b[39m overrides = dict_to_dot(config)\n\u001b[32m    515\u001b[39m config = load_config(config_path, overrides=overrides)\n\u001b[32m--> \u001b[39m\u001b[32m516\u001b[39m nlp = \u001b[43mload_model_from_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    517\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    518\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvocab\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvocab\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    519\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdisable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdisable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    520\u001b[39m \u001b[43m    \u001b[49m\u001b[43menable\u001b[49m\u001b[43m=\u001b[49m\u001b[43menable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    521\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexclude\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexclude\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    522\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmeta\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmeta\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    523\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    524\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m nlp.from_disk(model_path, exclude=exclude, overrides=overrides)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\casia\\testTAC\\tac\\.venv\\Lib\\site-packages\\spacy\\util.py:564\u001b[39m, in \u001b[36mload_model_from_config\u001b[39m\u001b[34m(config, meta, vocab, disable, enable, exclude, auto_fill, validate)\u001b[39m\n\u001b[32m    561\u001b[39m \u001b[38;5;66;03m# This will automatically handle all codes registered via the languages\u001b[39;00m\n\u001b[32m    562\u001b[39m \u001b[38;5;66;03m# registry, including custom subclasses provided via entry points\u001b[39;00m\n\u001b[32m    563\u001b[39m lang_cls = get_lang_class(nlp_config[\u001b[33m\"\u001b[39m\u001b[33mlang\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m--> \u001b[39m\u001b[32m564\u001b[39m nlp = \u001b[43mlang_cls\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    565\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    566\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvocab\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvocab\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    567\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdisable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdisable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    568\u001b[39m \u001b[43m    \u001b[49m\u001b[43menable\u001b[49m\u001b[43m=\u001b[49m\u001b[43menable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    569\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexclude\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexclude\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    570\u001b[39m \u001b[43m    \u001b[49m\u001b[43mauto_fill\u001b[49m\u001b[43m=\u001b[49m\u001b[43mauto_fill\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    571\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalidate\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalidate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    572\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmeta\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmeta\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    573\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    574\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m nlp\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\casia\\testTAC\\tac\\.venv\\Lib\\site-packages\\spacy\\language.py:1749\u001b[39m, in \u001b[36mLanguage.from_config\u001b[39m\u001b[34m(cls, config, vocab, disable, enable, exclude, meta, auto_fill, validate)\u001b[39m\n\u001b[32m   1747\u001b[39m     filled[\u001b[33m\"\u001b[39m\u001b[33mpretraining\u001b[39m\u001b[33m\"\u001b[39m] = orig_pretraining\n\u001b[32m   1748\u001b[39m     config[\u001b[33m\"\u001b[39m\u001b[33mpretraining\u001b[39m\u001b[33m\"\u001b[39m] = orig_pretraining\n\u001b[32m-> \u001b[39m\u001b[32m1749\u001b[39m resolved_nlp = \u001b[43mregistry\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresolve\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1750\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfilled\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mnlp\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidate\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalidate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m=\u001b[49m\u001b[43mConfigSchemaNlp\u001b[49m\n\u001b[32m   1751\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m create_tokenizer = resolved_nlp[\u001b[33m\"\u001b[39m\u001b[33mtokenizer\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1753\u001b[39m before_creation = resolved_nlp[\u001b[33m\"\u001b[39m\u001b[33mbefore_creation\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\casia\\testTAC\\tac\\.venv\\Lib\\site-packages\\confection\\__init__.py:760\u001b[39m, in \u001b[36mregistry.resolve\u001b[39m\u001b[34m(cls, config, schema, overrides, validate)\u001b[39m\n\u001b[32m    751\u001b[39m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[32m    752\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mresolve\u001b[39m(\n\u001b[32m    753\u001b[39m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    758\u001b[39m     validate: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    759\u001b[39m ) -> Dict[\u001b[38;5;28mstr\u001b[39m, Any]:\n\u001b[32m--> \u001b[39m\u001b[32m760\u001b[39m     resolved, _ = \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    761\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m=\u001b[49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moverrides\u001b[49m\u001b[43m=\u001b[49m\u001b[43moverrides\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidate\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalidate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresolve\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[32m    762\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    763\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m resolved\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\casia\\testTAC\\tac\\.venv\\Lib\\site-packages\\confection\\__init__.py:809\u001b[39m, in \u001b[36mregistry._make\u001b[39m\u001b[34m(cls, config, schema, overrides, resolve, validate)\u001b[39m\n\u001b[32m    807\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_interpolated:\n\u001b[32m    808\u001b[39m     config = Config(orig_config).interpolate()\n\u001b[32m--> \u001b[39m\u001b[32m809\u001b[39m filled, _, resolved = \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fill\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    810\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidate\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalidate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moverrides\u001b[49m\u001b[43m=\u001b[49m\u001b[43moverrides\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresolve\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresolve\u001b[49m\n\u001b[32m    811\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    812\u001b[39m filled = Config(filled, section_order=section_order)\n\u001b[32m    813\u001b[39m \u001b[38;5;66;03m# Check that overrides didn't include invalid properties not in config\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\casia\\testTAC\\tac\\.venv\\Lib\\site-packages\\confection\\__init__.py:863\u001b[39m, in \u001b[36mregistry._fill\u001b[39m\u001b[34m(cls, config, schema, validate, resolve, parent, overrides)\u001b[39m\n\u001b[32m    861\u001b[39m     field = schema.__fields__[key]\n\u001b[32m    862\u001b[39m     schema.__fields__[key] = copy_model_field(field, Any)\n\u001b[32m--> \u001b[39m\u001b[32m863\u001b[39m promise_schema = \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmake_promise_schema\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresolve\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresolve\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    864\u001b[39m filled[key], validation[v_key], final[key] = \u001b[38;5;28mcls\u001b[39m._fill(\n\u001b[32m    865\u001b[39m     value,\n\u001b[32m    866\u001b[39m     promise_schema,\n\u001b[32m   (...)\u001b[39m\u001b[32m    870\u001b[39m     overrides=overrides,\n\u001b[32m    871\u001b[39m )\n\u001b[32m    872\u001b[39m reg_name, func_name = \u001b[38;5;28mcls\u001b[39m.get_constructor(final[key])\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\casia\\testTAC\\tac\\.venv\\Lib\\site-packages\\confection\\__init__.py:1069\u001b[39m, in \u001b[36mregistry.make_promise_schema\u001b[39m\u001b[34m(cls, obj, resolve)\u001b[39m\n\u001b[32m   1067\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m resolve \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mcls\u001b[39m.has(reg_name, func_name):\n\u001b[32m   1068\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m EmptySchema\n\u001b[32m-> \u001b[39m\u001b[32m1069\u001b[39m func = \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreg_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1070\u001b[39m \u001b[38;5;66;03m# Read the argument annotations and defaults from the function signature\u001b[39;00m\n\u001b[32m   1071\u001b[39m id_keys = [k \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m obj.keys() \u001b[38;5;28;01mif\u001b[39;00m k.startswith(\u001b[33m\"\u001b[39m\u001b[33m@\u001b[39m\u001b[33m\"\u001b[39m)]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\casia\\testTAC\\tac\\.venv\\Lib\\site-packages\\spacy\\util.py:128\u001b[39m, in \u001b[36mregistry.get\u001b[39m\u001b[34m(cls, registry_name, func_name)\u001b[39m\n\u001b[32m    126\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mcls\u001b[39m, registry_name):\n\u001b[32m    127\u001b[39m     names = \u001b[33m\"\u001b[39m\u001b[33m, \u001b[39m\u001b[33m\"\u001b[39m.join(\u001b[38;5;28mcls\u001b[39m.get_registry_names()) \u001b[38;5;129;01mor\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mnone\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m128\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m RegistryError(Errors.E892.format(name=registry_name, available=names))\n\u001b[32m    129\u001b[39m reg = \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mcls\u001b[39m, registry_name)\n\u001b[32m    130\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[31mRegistryError\u001b[39m: [E892] Unknown function registry: 'vectors'.\n\nAvailable names: architectures, augmenters, batchers, callbacks, cli, datasets, displacy_colors, factories, initializers, languages, layers, lemmatizers, loggers, lookups, losses, misc, models, ops, optimizers, readers, schedules, scorers, tokenizers"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load('fr_core_news_md')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exemple sur un corpus de test fourni par SpaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Apple cherche à acheter une start-up anglaise pour 1 milliard de dollars',\n",
       " \"Les voitures autonomes déplacent la responsabilité de l'assurance vers les constructeurs\",\n",
       " \"San Francisco envisage d'interdire les robots coursiers sur les trottoirs\",\n",
       " 'Londres est une grande ville du Royaume-Uni',\n",
       " 'L’Italie choisit ArcelorMittal pour reprendre la plus grande aciérie d’Europe',\n",
       " \"Apple lance HomePod parce qu'il se sent menacé par l'Echo d'Amazon\",\n",
       " \"La France ne devrait pas manquer d'électricité cet été, même en cas de canicule\",\n",
       " 'Nouvelles attaques de Trump contre le maire de Londres',\n",
       " 'Où es-tu ?',\n",
       " 'Qui est le président de la France ?',\n",
       " 'Où est la capitale des États-Unis ?',\n",
       " 'Quand est né Barack Obama ?']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Imprimer le corpus de Spacy\n",
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Apple cherche à acheter une start-up anglaise pour 1 milliard de dollars'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Isoler la première phrase\n",
    "sent = sentences[0]\n",
    "sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Traiter la phrase avec Spacy\n",
    "doc = nlp(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.doc.Doc"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Apple cherche à acheter une start-up anglaise pour 1 milliard de dollars'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'Apple cherche à acheter une start-up anglaise pour 1 milliard de dollars',\n",
       " 'ents': [{'start': 0, 'end': 5, 'label': 'ORG'}],\n",
       " 'sents': [{'start': 0, 'end': 72}],\n",
       " 'tokens': [{'id': 0,\n",
       "   'start': 0,\n",
       "   'end': 5,\n",
       "   'tag': 'PROPN',\n",
       "   'pos': 'PROPN',\n",
       "   'morph': 'Gender=Masc|Number=Sing',\n",
       "   'lemma': 'Apple',\n",
       "   'dep': 'nsubj',\n",
       "   'head': 1},\n",
       "  {'id': 1,\n",
       "   'start': 6,\n",
       "   'end': 13,\n",
       "   'tag': 'VERB',\n",
       "   'pos': 'VERB',\n",
       "   'morph': 'Mood=Ind|Number=Sing|Person=3|Tense=Pres|VerbForm=Fin',\n",
       "   'lemma': 'cherche',\n",
       "   'dep': 'ROOT',\n",
       "   'head': 1},\n",
       "  {'id': 2,\n",
       "   'start': 14,\n",
       "   'end': 15,\n",
       "   'tag': 'ADP',\n",
       "   'pos': 'ADP',\n",
       "   'morph': '',\n",
       "   'lemma': 'à',\n",
       "   'dep': 'mark',\n",
       "   'head': 3},\n",
       "  {'id': 3,\n",
       "   'start': 16,\n",
       "   'end': 23,\n",
       "   'tag': 'VERB',\n",
       "   'pos': 'VERB',\n",
       "   'morph': 'VerbForm=Inf',\n",
       "   'lemma': 'acheter',\n",
       "   'dep': 'xcomp',\n",
       "   'head': 1},\n",
       "  {'id': 4,\n",
       "   'start': 24,\n",
       "   'end': 27,\n",
       "   'tag': 'DET',\n",
       "   'pos': 'DET',\n",
       "   'morph': 'Definite=Ind|Gender=Fem|Number=Sing|PronType=Art',\n",
       "   'lemma': 'un',\n",
       "   'dep': 'det',\n",
       "   'head': 5},\n",
       "  {'id': 5,\n",
       "   'start': 28,\n",
       "   'end': 33,\n",
       "   'tag': 'NOUN',\n",
       "   'pos': 'NOUN',\n",
       "   'morph': 'Gender=Fem|Number=Sing',\n",
       "   'lemma': 'start',\n",
       "   'dep': 'obj',\n",
       "   'head': 3},\n",
       "  {'id': 6,\n",
       "   'start': 33,\n",
       "   'end': 34,\n",
       "   'tag': 'PROPN',\n",
       "   'pos': 'PROPN',\n",
       "   'morph': '',\n",
       "   'lemma': '-',\n",
       "   'dep': 'obl:arg',\n",
       "   'head': 3},\n",
       "  {'id': 7,\n",
       "   'start': 34,\n",
       "   'end': 36,\n",
       "   'tag': 'X',\n",
       "   'pos': 'X',\n",
       "   'morph': '',\n",
       "   'lemma': 'up',\n",
       "   'dep': 'obl:arg',\n",
       "   'head': 3},\n",
       "  {'id': 8,\n",
       "   'start': 37,\n",
       "   'end': 45,\n",
       "   'tag': 'ADJ',\n",
       "   'pos': 'ADJ',\n",
       "   'morph': 'Gender=Fem|Number=Sing',\n",
       "   'lemma': 'anglais',\n",
       "   'dep': 'obj',\n",
       "   'head': 3},\n",
       "  {'id': 9,\n",
       "   'start': 46,\n",
       "   'end': 50,\n",
       "   'tag': 'ADP',\n",
       "   'pos': 'ADP',\n",
       "   'morph': '',\n",
       "   'lemma': 'pour',\n",
       "   'dep': 'case',\n",
       "   'head': 11},\n",
       "  {'id': 10,\n",
       "   'start': 51,\n",
       "   'end': 52,\n",
       "   'tag': 'NUM',\n",
       "   'pos': 'NUM',\n",
       "   'morph': 'NumType=Card',\n",
       "   'lemma': '1',\n",
       "   'dep': 'nummod',\n",
       "   'head': 11},\n",
       "  {'id': 11,\n",
       "   'start': 53,\n",
       "   'end': 61,\n",
       "   'tag': 'NOUN',\n",
       "   'pos': 'NOUN',\n",
       "   'morph': 'Gender=Masc|NumType=Card|Number=Sing',\n",
       "   'lemma': 'milliard',\n",
       "   'dep': 'obl:mod',\n",
       "   'head': 3},\n",
       "  {'id': 12,\n",
       "   'start': 62,\n",
       "   'end': 64,\n",
       "   'tag': 'ADP',\n",
       "   'pos': 'ADP',\n",
       "   'morph': '',\n",
       "   'lemma': 'de',\n",
       "   'dep': 'case',\n",
       "   'head': 13},\n",
       "  {'id': 13,\n",
       "   'start': 65,\n",
       "   'end': 72,\n",
       "   'tag': 'NOUN',\n",
       "   'pos': 'NOUN',\n",
       "   'morph': 'Gender=Masc|Number=Plur',\n",
       "   'lemma': 'dollar',\n",
       "   'dep': 'nmod',\n",
       "   'head': 11}]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.to_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Apple cherche à acheter une start-up anglaise pour 1 milliard de dollars' contient les entités suivantes : Apple (ORG)\n",
      "'Les voitures autonomes déplacent la responsabilité de l'assurance vers les constructeurs' ne contient aucune entité\n",
      "'San Francisco envisage d'interdire les robots coursiers sur les trottoirs' contient les entités suivantes : San Francisco (LOC)\n",
      "'Londres est une grande ville du Royaume-Uni' contient les entités suivantes : Londres (LOC), Royaume-Uni (LOC)\n",
      "'L’Italie choisit ArcelorMittal pour reprendre la plus grande aciérie d’Europe' contient les entités suivantes : L’Italie (LOC), ArcelorMittal (ORG), Europe (LOC)\n",
      "'Apple lance HomePod parce qu'il se sent menacé par l'Echo d'Amazon' contient les entités suivantes : Apple (ORG), HomePod (MISC), Echo (ORG), Amazon (ORG)\n",
      "'La France ne devrait pas manquer d'électricité cet été, même en cas de canicule' contient les entités suivantes : La France (LOC)\n",
      "'Nouvelles attaques de Trump contre le maire de Londres' contient les entités suivantes : Nouvelles attaques de (MISC), Trump (PER), Londres (LOC)\n",
      "'Où es-tu ?' ne contient aucune entité\n",
      "'Qui est le président de la France ?' contient les entités suivantes : la France (LOC)\n",
      "'Où est la capitale des États-Unis ?' contient les entités suivantes : États-Unis (LOC)\n",
      "'Quand est né Barack Obama ?' contient les entités suivantes : Barack Obama (PER)\n"
     ]
    }
   ],
   "source": [
    "# Appliquer le test sur toutes les phrases\n",
    "for sent in sentences:\n",
    "    doc = nlp(sent)\n",
    "    entities = []\n",
    "    for ent in doc.ents:\n",
    "        entities.append(f\"{ent.text} ({ent.label_})\")\n",
    "    if entities:\n",
    "        print(f\"'{doc.text}' contient les entités suivantes : {', '.join(entities)}\")\n",
    "    else:\n",
    "        print(f\"'{doc.text}' ne contient aucune entité\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appliquer la reconnaissance d'entités nommées sur notre corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger le texte\n",
    "n=1000000\n",
    "text = open(\"../data/all.txt\", encoding='utf-8').read()[:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 24.7 s, sys: 1.04 s, total: 25.7 s\n",
      "Wall time: 26 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Traiter le texte\n",
    "\n",
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compter les entités\n",
    "people = defaultdict(int)\n",
    "for ent in doc.ents:\n",
    "    if ent.label_ == \"PER\" and len(ent.text) > 3:\n",
    "        people[ent.text] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thérèse apparait 28 fois dans le corpus\n",
      "Guilbert apparait 22 fois dans le corpus\n",
      "M. Wilson apparait 20 fois dans le corpus\n",
      "Daubrac apparait 20 fois dans le corpus\n",
      "Gioconda apparait 19 fois dans le corpus\n",
      "Rossel apparait 19 fois dans le corpus\n",
      "Enguerrand apparait 17 fois dans le corpus\n",
      "Wilson apparait 15 fois dans le corpus\n",
      "Molière apparait 15 fois dans le corpus\n",
      "Parentis apparait 13 fois dans le corpus\n",
      "Edwige apparait 13 fois dans le corpus\n",
      "Savinien apparait 13 fois dans le corpus\n",
      "Octave apparait 12 fois dans le corpus\n",
      "Monsieur apparait 12 fois dans le corpus\n",
      "Grippe-Soleil apparait 11 fois dans le corpus\n",
      "duc d’Aumale apparait 11 fois dans le corpus\n",
      "Réclames apparait 10 fois dans le corpus\n",
      "Reine apparait 10 fois dans le corpus\n",
      "Ambassadeurs apparait 10 fois dans le corpus\n",
      "Jules Ferry apparait 9 fois dans le corpus\n",
      "Monseigneur apparait 9 fois dans le corpus\n",
      "Agence Rossel apparait 8 fois dans le corpus\n",
      "Henri apparait 8 fois dans le corpus\n",
      "Finet apparait 7 fois dans le corpus\n",
      "M. Graux apparait 7 fois dans le corpus\n",
      "Ali-Baba apparait 7 fois dans le corpus\n",
      "M. Vigneau apparait 7 fois dans le corpus\n",
      "M. Van Praet apparait 7 fois dans le corpus\n",
      "Aubertin apparait 6 fois dans le corpus\n",
      "Roux apparait 6 fois dans le corpus\n",
      "Marguerite apparait 6 fois dans le corpus\n",
      "Simon apparait 6 fois dans le corpus\n",
      "Bonhomme apparait 5 fois dans le corpus\n",
      "prince Baudouin apparait 5 fois dans le corpus\n",
      "Beernaert apparait 5 fois dans le corpus\n",
      "M. Finet apparait 5 fois dans le corpus\n",
      "Cockerill apparait 5 fois dans le corpus\n",
      "P Soc apparait 5 fois dans le corpus\n",
      "Charl apparait 5 fois dans le corpus\n",
      "Meyer apparait 5 fois dans le corpus\n",
      "Propriétaires apparait 5 fois dans le corpus\n",
      "Pollet apparait 5 fois dans le corpus\n",
      "Ponchielli apparait 5 fois dans le corpus\n",
      "Daubiehon apparait 5 fois dans le corpus\n",
      "Louvel apparait 4 fois dans le corpus\n",
      "Mme X. apparait 4 fois dans le corpus\n",
      "Joseph Bonhomme apparait 4 fois dans le corpus\n",
      "Beethoven apparait 4 fois dans le corpus\n",
      "Blanchisserie apparait 4 fois dans le corpus\n",
      "Jules Verne apparait 4 fois dans le corpus\n"
     ]
    }
   ],
   "source": [
    "# Trier et imprimer\n",
    "\n",
    "sorted_people = sorted(people.items(), key=lambda kv: kv[1], reverse=True)\n",
    "\n",
    "for person, freq in sorted_people[:50]:\n",
    "    print(f\"{person} apparait {freq} fois dans le corpus\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercice: essayez de lister les lieux (LOC) et les organisations (ORG) les plus mentionnées dans le corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
